{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [1:19:00<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [06:06<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:46<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for ant.' ë¬¸ì¥ì´ 'tortoise_output\\speech_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [1:01:02<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [05:58<00:00,  1.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for apple.' ë¬¸ì¥ì´ 'tortoise_output\\speech_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [12:51:48<00:00, 90.45s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [04:59<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for alligator.' ë¬¸ì¥ì´ 'tortoise_output\\speech_3.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 152/512 [19:22<45:53,  7.65s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# ìŒì„± ìƒì„± (voice_samplesê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í™”ìë¡œ ìƒì„±)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts(text\u001b[38;5;241m=\u001b[39mtext)  \u001b[38;5;66;03m# voice_samples ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•´ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜ í›„ ì €ì¥\u001b[39;00m\n\u001b[0;32m     27\u001b[0m audio_numpy \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# GPUì—ì„œ ì‘ì—…í•  ê²½ìš° CPUë¡œ ì´ë™\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:416\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporary_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive\n\u001b[0;32m    414\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m autoregressive, torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m--> 416\u001b[0m         codes \u001b[38;5;241m=\u001b[39m autoregressive\u001b[38;5;241m.\u001b[39minference_speech(auto_conditioning, text_tokens,\n\u001b[0;32m    417\u001b[0m                                                     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m                                                     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    419\u001b[0m                                                     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    420\u001b[0m                                                     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_batch_size,\n\u001b[0;32m    421\u001b[0m                                                     length_penalty\u001b[38;5;241m=\u001b[39mlength_penalty,\n\u001b[0;32m    422\u001b[0m                                                     repetition_penalty\u001b[38;5;241m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    423\u001b[0m                                                     max_generate_length\u001b[38;5;241m=\u001b[39mmax_mel_tokens,\n\u001b[0;32m    424\u001b[0m                                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    425\u001b[0m         padding_needed \u001b[38;5;241m=\u001b[39m max_mel_tokens \u001b[38;5;241m-\u001b[39m codes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    426\u001b[0m         codes \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(codes, (\u001b[38;5;241m0\u001b[39m, padding_needed), value\u001b[38;5;241m=\u001b[39mstop_mel_token)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:560\u001b[0m, in \u001b[0;36mUnifiedVoice.inference_speech\u001b[1;34m(self, speech_conditioning_latent, text_inputs, input_tokens, num_return_sequences, max_generate_length, typical_sampling, typical_mass, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m logits_processor \u001b[38;5;241m=\u001b[39m LogitsProcessorList([TypicalLogitsWarper(mass\u001b[38;5;241m=\u001b[39mtypical_mass)]) \u001b[38;5;28;01mif\u001b[39;00m typical_sampling \u001b[38;5;28;01melse\u001b[39;00m LogitsProcessorList()\n\u001b[0;32m    559\u001b[0m max_length \u001b[38;5;241m=\u001b[39m trunc_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_mel_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m max_generate_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m trunc_index \u001b[38;5;241m+\u001b[39m max_generate_length\n\u001b[1;32m--> 560\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model\u001b[38;5;241m.\u001b[39mgenerate(inputs, bos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_mel_token, pad_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token, eos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token,\n\u001b[0;32m    561\u001b[0m                                     max_length\u001b[38;5;241m=\u001b[39mmax_length, logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    562\u001b[0m                                     num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen[:, trunc_index:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2216\u001b[0m         input_ids,\n\u001b[0;32m   2217\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2218\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2219\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2220\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2221\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:150\u001b[0m, in \u001b[0;36mGPT2InferenceModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    146\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)\n\u001b[0;32m    147\u001b[0m     emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_pos_embedding\u001b[38;5;241m.\u001b[39mget_fixed_embedding(\n\u001b[0;32m    148\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mel_len, attention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 150\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    151\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m    152\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    153\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    154\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    155\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    156\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    157\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    158\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    159\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    160\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    161\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    162\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    164\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1122\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         output_attentions,\n\u001b[0;32m   1130\u001b[0m     )\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m   1133\u001b[0m         hidden_states,\n\u001b[0;32m   1134\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   1135\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1136\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m   1137\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1138\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1139\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1140\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1141\u001b[0m     )\n\u001b[0;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m    616\u001b[0m     hidden_states,\n\u001b[0;32m    617\u001b[0m     layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m    618\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    619\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    620\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    621\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    622\u001b[0m )\n\u001b[0;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:518\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    516\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_attn(hidden_states)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    520\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    521\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:111\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    110\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[1;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39maddmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Tortoise-TTS ëª¨ë¸ ë¡œë“œ\n",
    "tts = TextToSpeech()\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°\n",
    "input_file = \"input_level1.txt\"\n",
    "output_folder = \"tortoise_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ìŒì„± ìƒ˜í”Œ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš° í™”ì ìŠ¤íƒ€ì¼ ì§€ì •\n",
    "# voice_samples = [\"path/to/sample1.wav\", \"path/to/sample2.wav\"]  # í™”ì ìŒì„± ìƒ˜í”Œì´ ìˆì„ ê²½ìš° ì„¤ì •\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        \n",
    "        # ìŒì„± ìƒì„± (voice_samplesê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í™”ìë¡œ ìƒì„±)\n",
    "        audio = tts.tts(text=text)  # voice_samples ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•´ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "        # í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜ í›„ ì €ì¥\n",
    "        audio_numpy = audio.cpu().numpy()  # GPUì—ì„œ ì‘ì—…í•  ê²½ìš° CPUë¡œ ì´ë™\n",
    "        output_path = os.path.join(output_folder, f\"speech_{idx+1}.wav\")\n",
    "        write(output_path, 22050, audio_numpy)  # 22050ì€ í‘œì¤€ ìƒ˜í”Œë§ ë ˆì´íŠ¸ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    }
   ],
   "source": [
    "# Tortoise-TTS ëª¨ë¸ ë¡œë“œ\n",
    "tts = TextToSpeech()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LJSpeech ìŒì„± ìƒ˜í”Œ íŒŒì¼ì„ torch.Tensorë¡œ ë¡œë“œ\n",
    "voice_samples = []\n",
    "for sample_path in [\"LJ001-0001.wav\", \"LJ001-0002.wav\"]:\n",
    "    waveform, sample_rate = torchaudio.load(sample_path)\n",
    "    voice_samples.append(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€í™˜í•  í…ìŠ¤íŠ¸\n",
    "text = \"This is an example that specifies the speaker style using the LJSpeech dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 31/512 [20:47<5:22:38, 40.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Tortoise-TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ìƒì„±\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts(text\u001b[38;5;241m=\u001b[39mtext, voice_samples\u001b[38;5;241m=\u001b[39mvoice_samples)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:416\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporary_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive\n\u001b[0;32m    414\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m autoregressive, torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m--> 416\u001b[0m         codes \u001b[38;5;241m=\u001b[39m autoregressive\u001b[38;5;241m.\u001b[39minference_speech(auto_conditioning, text_tokens,\n\u001b[0;32m    417\u001b[0m                                                     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m                                                     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    419\u001b[0m                                                     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    420\u001b[0m                                                     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_batch_size,\n\u001b[0;32m    421\u001b[0m                                                     length_penalty\u001b[38;5;241m=\u001b[39mlength_penalty,\n\u001b[0;32m    422\u001b[0m                                                     repetition_penalty\u001b[38;5;241m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    423\u001b[0m                                                     max_generate_length\u001b[38;5;241m=\u001b[39mmax_mel_tokens,\n\u001b[0;32m    424\u001b[0m                                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    425\u001b[0m         padding_needed \u001b[38;5;241m=\u001b[39m max_mel_tokens \u001b[38;5;241m-\u001b[39m codes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    426\u001b[0m         codes \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(codes, (\u001b[38;5;241m0\u001b[39m, padding_needed), value\u001b[38;5;241m=\u001b[39mstop_mel_token)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:560\u001b[0m, in \u001b[0;36mUnifiedVoice.inference_speech\u001b[1;34m(self, speech_conditioning_latent, text_inputs, input_tokens, num_return_sequences, max_generate_length, typical_sampling, typical_mass, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m logits_processor \u001b[38;5;241m=\u001b[39m LogitsProcessorList([TypicalLogitsWarper(mass\u001b[38;5;241m=\u001b[39mtypical_mass)]) \u001b[38;5;28;01mif\u001b[39;00m typical_sampling \u001b[38;5;28;01melse\u001b[39;00m LogitsProcessorList()\n\u001b[0;32m    559\u001b[0m max_length \u001b[38;5;241m=\u001b[39m trunc_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_mel_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m max_generate_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m trunc_index \u001b[38;5;241m+\u001b[39m max_generate_length\n\u001b[1;32m--> 560\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model\u001b[38;5;241m.\u001b[39mgenerate(inputs, bos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_mel_token, pad_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token, eos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token,\n\u001b[0;32m    561\u001b[0m                                     max_length\u001b[38;5;241m=\u001b[39mmax_length, logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    562\u001b[0m                                     num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen[:, trunc_index:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2216\u001b[0m         input_ids,\n\u001b[0;32m   2217\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2218\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2219\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2220\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2221\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:150\u001b[0m, in \u001b[0;36mGPT2InferenceModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    146\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)\n\u001b[0;32m    147\u001b[0m     emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_pos_embedding\u001b[38;5;241m.\u001b[39mget_fixed_embedding(\n\u001b[0;32m    148\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mel_len, attention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 150\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    151\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m    152\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    153\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    154\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    155\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    156\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    157\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    158\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    159\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    160\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    161\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    162\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    164\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1122\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         output_attentions,\n\u001b[0;32m   1130\u001b[0m     )\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m   1133\u001b[0m         hidden_states,\n\u001b[0;32m   1134\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   1135\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1136\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m   1137\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1138\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1139\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1140\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1141\u001b[0m     )\n\u001b[0;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:652\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    650\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    651\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 652\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m    654\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:576\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    575\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m--> 576\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[0;32m    577\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[0;32m    578\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\activations.py:56\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.044715\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m3.0\u001b[39m))))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tortoise-TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ìƒì„±\n",
    "\n",
    "audio = tts.tts(text=text, voice_samples=voice_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥\n",
    "output_path = \"output_ljspeech_style.wav\"\n",
    "audio_numpy = audio.cpu().numpy()\n",
    "write(output_path, 22050, audio_numpy)\n",
    "\n",
    "print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì˜¤ë””ì˜¤ì˜ ìƒ˜í”Œë§ ì†ë„ëŠ” 22050 Hzì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
    "audio_path = \"LJ001-0001.wav\"\n",
    "\n",
    "# ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ìƒ˜í”Œë§ ì†ë„ í™•ì¸\n",
    "data, sample_rate = librosa.load(audio_path, sr=None)  # sr=Noneìœ¼ë¡œ ì§€ì •í•˜ë©´ ì›ë³¸ ìƒ˜í”Œë§ ì†ë„ ìœ ì§€\n",
    "print(f\"ì›ë³¸ ì˜¤ë””ì˜¤ì˜ ìƒ˜í”Œë§ ì†ë„ëŠ” {sample_rate} Hzì…ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜êµ­ì—¬ì ìƒ˜í”Œ 1 -> ìŒì„±ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise import utils\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C is for cat.' ë¬¸ì¥ì´ 'tortoise_output1\\tortoise_test_ultra_fast.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥í•  í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "output_folder = 'tortoise_output1'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# 22,050Hz ìƒ˜í”Œë§ ì†ë„ì˜ ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì‚¬ìš©\n",
    "voice_samples = [utils.audio.load_audio(\"LJ001-0001.wav\", 22050)]\n",
    "\n",
    "# Tortoiseì— í™”ì í”„ë¡œí•„ ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# ì˜ˆì‹œìš© í…ìŠ¤íŠ¸\n",
    "text = \"C is for cat.\"\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "output_path = os.path.join(output_folder, 'tortoise_test_ultra_fast.wav')\n",
    "write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜êµ­ì—¬ì ìƒ˜í”Œ 5 -> ìŒì„±ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise import utils\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥í•  í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "output_folder = 'tortoise_output_seeker'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# ì—¬ëŸ¬ ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í™”ì ìƒ˜í”Œë¡œ ì‚¬ìš©\n",
    "sample_audio_files = [\"storyofthetreasureseekersversion3_01_nesbit_64kb.mp3\", \"storyofthetreasureseekersversion3_02_nesbit_64kb.mp3\", \"storyofthetreasureseekersversion3_03_nesbit_64kb.mp3\"]\n",
    "voice_samples = [utils.audio.load_audio(sample, 22050) for sample in sample_audio_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    }
   ],
   "source": [
    "# Tortoiseì— ì—¬ëŸ¬ ìƒ˜í”Œë¡œ í™”ì í”„ë¡œí•„ ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# ì•ŒíŒŒë²³ì„ ì›í•˜ëŠ” ë°œìŒìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def replace_alphabets(text):\n",
    "    alphabet_dict = {\n",
    "        'A': 'ì—ì´', 'B': 'ë¹„', 'C': 'ì”¨', 'D': 'ë””', 'E': 'ì´',\n",
    "        'F': 'ì—í”„', 'G': 'ì§€', 'H': 'ì—ì´ì¹˜', 'I': 'ì•„ì´', 'J': 'ì œì´',\n",
    "        'K': 'ì¼€ì´', 'L': 'ì—˜', 'M': 'ì— ', 'N': 'ì—”', 'O': 'ì˜¤',\n",
    "        'P': 'í”¼', 'Q': 'í', 'R': 'ì•„ë¥´', 'S': 'ì—ìŠ¤', 'T': 'í‹°',\n",
    "        'U': 'ìœ ', 'V': 'ë¸Œì´', 'W': 'ë”ë¸”ìœ ', 'X': 'ì—‘ìŠ¤', 'Y': 'ì™€ì´', 'Z': 'ì§€'\n",
    "    }\n",
    "    words = text.split()\n",
    "    return ' '.join([alphabet_dict.get(word, word) for word in words])\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for ant.' ë¬¸ì¥ì´ 'tortoise_output_seeker\\tortoise_ultra_fast_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for apple.' ë¬¸ì¥ì´ 'tortoise_output_seeker\\tortoise_ultra_fast_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:16<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for alligator.' ë¬¸ì¥ì´ 'tortoise_output_seeker\\tortoise_ultra_fast_3.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     15\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtortoise_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:416\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporary_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive\n\u001b[0;32m    414\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m autoregressive, torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m--> 416\u001b[0m         codes \u001b[38;5;241m=\u001b[39m autoregressive\u001b[38;5;241m.\u001b[39minference_speech(auto_conditioning, text_tokens,\n\u001b[0;32m    417\u001b[0m                                                     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m                                                     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    419\u001b[0m                                                     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    420\u001b[0m                                                     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_batch_size,\n\u001b[0;32m    421\u001b[0m                                                     length_penalty\u001b[38;5;241m=\u001b[39mlength_penalty,\n\u001b[0;32m    422\u001b[0m                                                     repetition_penalty\u001b[38;5;241m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    423\u001b[0m                                                     max_generate_length\u001b[38;5;241m=\u001b[39mmax_mel_tokens,\n\u001b[0;32m    424\u001b[0m                                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    425\u001b[0m         padding_needed \u001b[38;5;241m=\u001b[39m max_mel_tokens \u001b[38;5;241m-\u001b[39m codes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    426\u001b[0m         codes \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(codes, (\u001b[38;5;241m0\u001b[39m, padding_needed), value\u001b[38;5;241m=\u001b[39mstop_mel_token)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:560\u001b[0m, in \u001b[0;36mUnifiedVoice.inference_speech\u001b[1;34m(self, speech_conditioning_latent, text_inputs, input_tokens, num_return_sequences, max_generate_length, typical_sampling, typical_mass, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m logits_processor \u001b[38;5;241m=\u001b[39m LogitsProcessorList([TypicalLogitsWarper(mass\u001b[38;5;241m=\u001b[39mtypical_mass)]) \u001b[38;5;28;01mif\u001b[39;00m typical_sampling \u001b[38;5;28;01melse\u001b[39;00m LogitsProcessorList()\n\u001b[0;32m    559\u001b[0m max_length \u001b[38;5;241m=\u001b[39m trunc_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_mel_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m max_generate_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m trunc_index \u001b[38;5;241m+\u001b[39m max_generate_length\n\u001b[1;32m--> 560\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model\u001b[38;5;241m.\u001b[39mgenerate(inputs, bos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_mel_token, pad_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token, eos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token,\n\u001b[0;32m    561\u001b[0m                                     max_length\u001b[38;5;241m=\u001b[39mmax_length, logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    562\u001b[0m                                     num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen[:, trunc_index:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2216\u001b[0m         input_ids,\n\u001b[0;32m   2217\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2218\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2219\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2220\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2221\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:150\u001b[0m, in \u001b[0;36mGPT2InferenceModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    146\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)\n\u001b[0;32m    147\u001b[0m     emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_pos_embedding\u001b[38;5;241m.\u001b[39mget_fixed_embedding(\n\u001b[0;32m    148\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mel_len, attention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 150\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    151\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m    152\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    153\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    154\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    155\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    156\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    157\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    158\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    159\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    160\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    161\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    162\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    164\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1122\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         output_attentions,\n\u001b[0;32m   1130\u001b[0m     )\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m   1133\u001b[0m         hidden_states,\n\u001b[0;32m   1134\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   1135\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1136\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m   1137\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1138\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1139\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1140\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1141\u001b[0m     )\n\u001b[0;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m    616\u001b[0m     hidden_states,\n\u001b[0;32m    617\u001b[0m     layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m    618\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    619\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    620\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    621\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    622\u001b[0m )\n\u001b[0;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:559\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    556\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Final projection\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n\u001b[0;32m    560\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(attn_output)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, present, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:111\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    110\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[1;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39maddmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "        text = line.strip()\n",
    "        \n",
    "        # ë¹ˆ ì¤„ì€ ê±´ë„ˆë›°ê¸°\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp3 -> wav -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'emilyclimbs_01_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_02_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_03_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_04_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_05_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_06_Montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_07_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_08_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_09_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_10_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_11_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_12_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_13_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_14_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_15_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_16_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_17_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_18_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_19_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_20_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_21_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_22_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_23_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_24_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_25_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™”ì ì„ë² ë”©ì´ 'saved_embeddings/conditioning_latents_emilyclimbs.npz'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "\n",
    "# Tortoise TTS ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# MP3 íŒŒì¼ì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œì™€ ë³€í™˜ëœ WAV íŒŒì¼ì„ ì €ì¥í•  í´ë” ê²½ë¡œ\n",
    "mp3_folder = \"emilyclimbs_2204_librivox\"  # MP3 íŒŒì¼ í´ë” ê²½ë¡œ\n",
    "wav_folder = \"emilyclimbs_wav_files\"  # WAV íŒŒì¼ì´ ì €ì¥ë  í´ë” ê²½ë¡œ\n",
    "os.makedirs(wav_folder, exist_ok=True)\n",
    "\n",
    "# ë³€í™˜ëœ WAV íŒŒì¼ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "wav_files = []\n",
    "\n",
    "# MP3 íŒŒì¼ì„ WAVë¡œ ë³€í™˜\n",
    "for mp3_file in os.listdir(mp3_folder):\n",
    "    if mp3_file.endswith(\".mp3\"):\n",
    "        mp3_path = os.path.join(mp3_folder, mp3_file)\n",
    "        \n",
    "        # MP3ë¥¼ ë¡œë“œí•˜ì—¬ WAVë¡œ ë³€í™˜\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "        audio = audio.set_frame_rate(22050).set_channels(1)  # ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ì±„ë„ ì„¤ì •\n",
    "        wav_path = os.path.join(wav_folder, mp3_file.replace(\".mp3\", \".wav\"))\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        wav_files.append(wav_path)\n",
    "        print(f\"'{mp3_file}'ì´ '{wav_path}'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë³€í™˜ëœ WAV íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì—¬ ì„ë² ë”© ìƒì„±\n",
    "voice_samples = []\n",
    "for wav_file in wav_files:\n",
    "    try:\n",
    "        # WAV íŒŒì¼ì„ ì½ê³  ì •ê·œí™”í•˜ì—¬ í…ì„œë¡œ ë³€í™˜\n",
    "        sr, wav_audio = read_wav(wav_file)\n",
    "        \n",
    "        # ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš° ëª¨ë…¸ë¡œ ë³€í™˜\n",
    "        if wav_audio.ndim > 1:\n",
    "            wav_audio = wav_audio.mean(axis=1)\n",
    "        \n",
    "        # ì •ê·œí™”: -1 ~ 1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "        wav_audio = wav_audio / np.max(np.abs(wav_audio))  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "        \n",
    "        # torch.Tensorë¡œ ë³€í™˜í•˜ê³  ì°¨ì› ì¶”ê°€\n",
    "        audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)  # (1, ìƒ˜í”Œ ê¸¸ì´)\n",
    "        voice_samples.append(audio_tensor)\n",
    "        print(f\"WAV íŒŒì¼ '{wav_file}'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"{wav_file} ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# ì„ë² ë”©ì„ ì €ì¥í•  ê²½ë¡œ\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_emilyclimbs.npz\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"í™”ì ì„ë² ë”©ì´ '{embedding_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m4b -> wav ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2-full_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Skipping unhandled metadata genre of type 18\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Unknown cover type: 0x0.\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'GalacticPatrol2_librivox.m4b':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "    media_type      : 2\n",
      "    encoder         : Chapter and Verse V 1.5\n",
      "    title           : GalacticPatrol2_librivox\n",
      "    artist          : E. E. Smith\n",
      "    album           : Galactic Patrol (version 2)\n",
      "    comment         : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    track           : 1\n",
      "    Encoding Params : vers\n",
      "  Duration: 08:39:15.88, start: 0.000000, bitrate: 64 kb/s\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 62 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Data: bin_data (text / 0x74786574)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T11:00:28.000000Z\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'GalacticPatrol2.wav':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    Encoding Params : vers\n",
      "    media_type      : 2\n",
      "    IPRT            : 1\n",
      "    INAM            : GalacticPatrol2_librivox\n",
      "    IART            : E. E. Smith\n",
      "    IPRD            : Galactic Patrol (version 2)\n",
      "    ICMT            : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   74496KiB time=00:28:52.20 bitrate= 352.3kbits/s speed=3.33e+03x    \n",
      "size=  146432KiB time=00:56:46.27 bitrate= 352.2kbits/s speed=3.29e+03x    \n",
      "size=  219648KiB time=01:25:02.51 bitrate= 352.6kbits/s speed=3.28e+03x    \n",
      "size=  293888KiB time=01:53:44.39 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  368384KiB time=02:22:37.94 bitrate= 352.6kbits/s speed=3.31e+03x    \n",
      "size=  443136KiB time=02:51:35.61 bitrate= 352.6kbits/s speed=3.32e+03x    \n",
      "size=  513280KiB time=03:18:40.98 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  587776KiB time=03:47:32.10 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  662784KiB time=04:16:32.85 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  738816KiB time=04:45:55.94 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  810496KiB time=05:13:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  885760KiB time=05:42:49.46 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  955648KiB time=06:09:54.58 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1026048KiB time=06:37:09.19 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size= 1103616KiB time=07:07:10.69 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1177344KiB time=07:35:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1249536KiB time=08:03:36.83 bitrate= 352.8kbits/s speed=3.3e+03x    \n",
      "size= 1320448KiB time=08:31:06.87 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "[out#0/wav @ 000001e55d03ba80] video:0KiB audio:1341772KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000018%\n",
      "size= 1341772KiB time=08:39:15.88 bitrate= 352.8kbits/s speed=3.27e+03x    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i GalacticPatrol2_librivox.m4b -ac 1 -ar 22050 GalacticPatrol2.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì„ë² ë”© ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import read as read_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "wav_path = \"GalacticPatrol2.wav\"  # ë³€í™˜ëœ WAV íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# WAV íŒŒì¼ì„ ë¡œë“œí•˜ê³  í…ì„œë¡œ ë³€í™˜\n",
    "try:\n",
    "    sr, wav_audio = read_wav(wav_path)\n",
    "    \n",
    "    # ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš° ëª¨ë…¸ë¡œ ë³€í™˜\n",
    "    if wav_audio.ndim > 1:\n",
    "        wav_audio = wav_audio.mean(axis=1)\n",
    "\n",
    "    # ì •ê·œí™”: -1 ~ 1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    wav_audio = wav_audio / np.max(np.abs(wav_audio))  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "\n",
    "    # torch.Tensorë¡œ ë³€í™˜í•˜ê³  ì°¨ì› ì¶”ê°€\n",
    "    audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)\n",
    "    print(f\"WAV íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"WAV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™”ì ì„ë² ë”©ì´ 'saved_embeddings/conditioning_latents_GalacticPatrol2'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTSì—ì„œ í™”ì í”„ë¡œí•„ ì„ë² ë”© ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents([audio_tensor])\n",
    "\n",
    "# ì„ë² ë”© ì €ì¥\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_GalacticPatrol2\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"í™”ì ì„ë² ë”©ì´ '{embedding_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeconSecondReader ì„ë² ë”©ìœ¼ë¡œ ìŒì„± ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for ant.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1_embeddings1\\tortoise_test_ultra_fast_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for apple.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1_embeddings1\\tortoise_test_ultra_fast_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:12<00:27,  2.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     32\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtortoise_test_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:416\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporary_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive\n\u001b[0;32m    414\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m autoregressive, torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m--> 416\u001b[0m         codes \u001b[38;5;241m=\u001b[39m autoregressive\u001b[38;5;241m.\u001b[39minference_speech(auto_conditioning, text_tokens,\n\u001b[0;32m    417\u001b[0m                                                     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m                                                     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    419\u001b[0m                                                     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    420\u001b[0m                                                     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_batch_size,\n\u001b[0;32m    421\u001b[0m                                                     length_penalty\u001b[38;5;241m=\u001b[39mlength_penalty,\n\u001b[0;32m    422\u001b[0m                                                     repetition_penalty\u001b[38;5;241m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    423\u001b[0m                                                     max_generate_length\u001b[38;5;241m=\u001b[39mmax_mel_tokens,\n\u001b[0;32m    424\u001b[0m                                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    425\u001b[0m         padding_needed \u001b[38;5;241m=\u001b[39m max_mel_tokens \u001b[38;5;241m-\u001b[39m codes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    426\u001b[0m         codes \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(codes, (\u001b[38;5;241m0\u001b[39m, padding_needed), value\u001b[38;5;241m=\u001b[39mstop_mel_token)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:560\u001b[0m, in \u001b[0;36mUnifiedVoice.inference_speech\u001b[1;34m(self, speech_conditioning_latent, text_inputs, input_tokens, num_return_sequences, max_generate_length, typical_sampling, typical_mass, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m logits_processor \u001b[38;5;241m=\u001b[39m LogitsProcessorList([TypicalLogitsWarper(mass\u001b[38;5;241m=\u001b[39mtypical_mass)]) \u001b[38;5;28;01mif\u001b[39;00m typical_sampling \u001b[38;5;28;01melse\u001b[39;00m LogitsProcessorList()\n\u001b[0;32m    559\u001b[0m max_length \u001b[38;5;241m=\u001b[39m trunc_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_mel_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m max_generate_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m trunc_index \u001b[38;5;241m+\u001b[39m max_generate_length\n\u001b[1;32m--> 560\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model\u001b[38;5;241m.\u001b[39mgenerate(inputs, bos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_mel_token, pad_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token, eos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_mel_token,\n\u001b[0;32m    561\u001b[0m                                     max_length\u001b[38;5;241m=\u001b[39mmax_length, logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    562\u001b[0m                                     num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen[:, trunc_index:]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2216\u001b[0m         input_ids,\n\u001b[0;32m   2217\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2218\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2219\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2220\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2221\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\autoregressive.py:150\u001b[0m, in \u001b[0;36mGPT2InferenceModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    146\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)\n\u001b[0;32m    147\u001b[0m     emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_pos_embedding\u001b[38;5;241m.\u001b[39mget_fixed_embedding(\n\u001b[0;32m    148\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m mel_len, attention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 150\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    151\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m    152\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    153\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    154\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    155\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    156\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    157\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    158\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    159\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    160\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    161\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    162\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    164\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1122\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         output_attentions,\n\u001b[0;32m   1130\u001b[0m     )\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m   1133\u001b[0m         hidden_states,\n\u001b[0;32m   1134\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   1135\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1136\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m   1137\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1138\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1139\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1140\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1141\u001b[0m     )\n\u001b[0;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:651\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    648\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attn_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m    650\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 651\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m    652\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps\n\u001b[0;32m    219\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2892\u001b[0m         layer_norm,\n\u001b[0;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2899\u001b[0m     )\n\u001b[1;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[0;32m   2901\u001b[0m     \u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m   2902\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings1/conditioning_latents.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key]) for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_standard_level1_embeddings1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ì „ì²˜ë¦¬ ì ìš©\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í”¼ë…¸í‚¤ì˜¤ ìŒì„±ìœ¼ë¡œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:03<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:42<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:13<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for ant.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:58<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:42<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:16<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for apple.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:06<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:42<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:17<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for alligator.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_3.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:03<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:41<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:16<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for airplane.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_4.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:02<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:39<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:15<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for arm.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_5.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:57<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:40<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:16<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for ball.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_6.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:47<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for banana.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_7.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:39<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for bed.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_8.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:58<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:39<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:13<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for bird.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_9.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:56<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for book.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_10.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cat.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_11.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for car.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_12.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:37<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cake.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_13.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cup.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_14.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:39<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cow.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_15.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:13<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for dog.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_16.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:56<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for duck.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_17.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:15<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for door.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_18.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:46<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for drum.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_19.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for doll.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_20.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for egg.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_21.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:39<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for elephant.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_22.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:41<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for envelope.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_23.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:37<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for ear.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_24.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for elbow.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_25.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for fish.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_26.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for frog.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_27.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for fan.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_28.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for foot.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_29.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for fork.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_30.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'G, is for goat.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_31.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'G, is for gift.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_32.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'G, is for girl.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_33.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'G, is for gum.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_34.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'G, is for gold.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_35.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'H, is for hat.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_36.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'H, is for hand.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_37.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'H, is for house.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_38.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'H, is for horse.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_39.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'H, is for hill.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_40.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I, is for igloo.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_41.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:40<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I, is for insect.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_42.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:36<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I, is for ice.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_43.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:37<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I, is for island.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_44.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:40<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I, is for idea.' ë¬¸ì¥ì´ 'tortoise_output_standard_level1\\tortoise_test_ultra_fast_45.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:07<00:01,  1.67it/s]"
     ]
    }
   ],
   "source": [
    "## í”¼ë…¸í‚¤ì˜¤\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_pino.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key]) for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_standard_level1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ì „ì²˜ë¦¬ ì ìš©\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kittys ì„ë² ë”©ìœ¼ë¡œ ìŒì„± ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:48<00:00, 14.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.48it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m processed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[enunciate] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(processed_text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     33\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtortoise_test_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:587\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner\u001b[38;5;241m.\u001b[39mredact(clip\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), text)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clip\n\u001b[1;32m--> 587\u001b[0m wav_candidates \u001b[38;5;241m=\u001b[39m [potentially_redact(wav_candidate, text) \u001b[38;5;28;01mfor\u001b[39;00m wav_candidate \u001b[38;5;129;01min\u001b[39;00m wav_candidates]\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(wav_candidates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    590\u001b[0m     res \u001b[38;5;241m=\u001b[39m wav_candidates\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:585\u001b[0m, in \u001b[0;36mTextToSpeech.tts.<locals>.potentially_redact\u001b[1;34m(clip, text)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpotentially_redact\u001b[39m(clip, text):\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_redaction:\n\u001b[1;32m--> 585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner\u001b[38;5;241m.\u001b[39mredact(clip\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), text)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clip\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\utils\\wav2vec_alignment.py:144\u001b[0m, in \u001b[0;36mWav2VecAlignment.redact\u001b[1;34m(self, audio, expected_text, audio_sample_rate)\u001b[0m\n\u001b[0;32m    141\u001b[0m     last_point \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fully_split[i])\n\u001b[0;32m    143\u001b[0m bare_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fully_split)\n\u001b[1;32m--> 144\u001b[0m alignments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign(audio, bare_text, audio_sample_rate)\n\u001b[0;32m    146\u001b[0m output_audio \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nri \u001b[38;5;129;01min\u001b[39;00m non_redacted_intervals:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\utils\\wav2vec_alignment.py:62\u001b[0m, in \u001b[0;36mWav2VecAlignment.align\u001b[1;34m(self, audio, expected_text, audio_sample_rate)\u001b[0m\n\u001b[0;32m     59\u001b[0m orig_len \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     63\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     64\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mresample(audio, audio_sample_rate, \u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3156\u001b[0m         )\n\u001b[1;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1327\u001b[0m         device,\n\u001b[0;32m   1328\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1329\u001b[0m         non_blocking,\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_KittysEnemy.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key]) for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_kittys_level1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ í…ìŠ¤íŠ¸ì— '[enunciate]' íƒœê·¸ ì¶”ê°€\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        processed_text = f\"[enunciate] {text}\"\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(processed_text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{processed_text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tortoise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threads ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:56<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:46<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for ant.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:50<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:45<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for apple.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:58<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:10<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for alligator.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_3.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:34<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for airplane.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_4.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A, is for arm.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_5.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for ball.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_6.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:30<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for banana.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_7.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for bed.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_8.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for bird.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_9.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B, is for book.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_10.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:28<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cat.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_11.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:10<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for car.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_12.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:32<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:10<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cake.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_13.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:10<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cup.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_14.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C, is for cow.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_15.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for dog.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_16.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for duck.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_17.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for door.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_18.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for drum.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_19.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'D, is for doll.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_20.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for egg.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_21.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for elephant.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_22.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for envelope.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_23.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:28<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for ear.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_24.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:29<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E, is for elbow.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_25.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for fish.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_26.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [13:11<00:00, 49.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for frog.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_27.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for fan.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_28.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:44<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:46<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:15<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'F, is for foot.' ë¬¸ì¥ì´ 'tortoise_output_EightGirl_level1\\tortoise_test_ultra_fast_29.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:35<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:02<00:07,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     29\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtortoise_test_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:463\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m     batch[i] \u001b[38;5;241m=\u001b[39m fix_autoregressive_output(batch[i], stop_mel_token)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cvvp_amount \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 463\u001b[0m     clvp_out \u001b[38;5;241m=\u001b[39m clvp(text_tokens\u001b[38;5;241m.\u001b[39mrepeat(batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m), batch, return_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_conds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m cvvp_amount \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    465\u001b[0m     cvvp_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\clvp.py:120\u001b[0m, in \u001b[0;36mCLVP.forward\u001b[1;34m(self, text, speech_tokens, return_loss)\u001b[0m\n\u001b[0;32m    117\u001b[0m     text_emb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_pos_emb(torch\u001b[38;5;241m.\u001b[39marange(text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    118\u001b[0m     speech_emb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeech_pos_emb(torch\u001b[38;5;241m.\u001b[39marange(speech_emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m--> 120\u001b[0m enc_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_transformer(text_emb, mask\u001b[38;5;241m=\u001b[39mtext_mask)\n\u001b[0;32m    121\u001b[0m enc_speech \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeech_transformer(speech_emb, mask\u001b[38;5;241m=\u001b[39mvoice_mask)\n\u001b[0;32m    123\u001b[0m text_latents \u001b[38;5;241m=\u001b[39m masked_mean(enc_text, text_mask, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:370\u001b[0m, in \u001b[0;36mCheckpointedXTransformerEncoder.forward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_permute:\n\u001b[0;32m    369\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 370\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_permute:\n\u001b[0;32m    372\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\xtransformers.py:1233\u001b[0m, in \u001b[0;36mContinuousTransformerWrapper.forward\u001b[1;34m(self, x, return_embeddings, mask, return_attn, mems, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(x)\n\u001b[0;32m   1231\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dropout(x)\n\u001b[1;32m-> 1233\u001b[0m x, intermediates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers(x, mask\u001b[38;5;241m=\u001b[39mmask, mems\u001b[38;5;241m=\u001b[39mmems, return_hiddens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m   1236\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_out(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_embeddings \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\xtransformers.py:977\u001b[0m, in \u001b[0;36mAttentionLayers.forward\u001b[1;34m(self, x, context, full_context, mask, context_mask, attn_mask, mems, return_hiddens, norm_scale_shift_inp, past_key_values, expected_seq_len)\u001b[0m\n\u001b[0;32m    975\u001b[0m         out, inter, k, v \u001b[38;5;241m=\u001b[39m block(x, context, mask, context_mask, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, prev_attn, \u001b[38;5;28;01mNone\u001b[39;00m, layer_past)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 977\u001b[0m     out \u001b[38;5;241m=\u001b[39m block(x)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m present_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    980\u001b[0m     present_key_values\u001b[38;5;241m.\u001b[39mappend((k\u001b[38;5;241m.\u001b[39mdetach(), v\u001b[38;5;241m.\u001b[39mdetach()))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:347\u001b[0m, in \u001b[0;36mCheckpointedLayer.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mrequires_grad)  \u001b[38;5;66;03m# This would screw up checkpointing.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m partial \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial(x, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\xtransformers.py:474\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# CPUì—ì„œ ì‚¬ìš©í•  ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •\n",
    "torch.set_num_threads(10)  # ìì‹ ì˜ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì„¤ì •í•˜ì„¸ìš”.\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_EightGirl.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key]) for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_EightGirl_level1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ì „ì²˜ë¦¬ ì ìš©\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threads & alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:13<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì—ì´ is for ant' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_1.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:04<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì—ì´ is for apple' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_2.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:27<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì—ì´ is for alligator' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_3.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:25<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì—ì´ is for airplane' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_4.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:57<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì—ì´ is for arm' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_5.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:50<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:46<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bee is for ball' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_6.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [04:10<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bee is for banana' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_7.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:29<00:00,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:32<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:10<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bee is for bed' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_8.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:45<00:00,  6.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:35<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:12<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bee is for bird' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_9.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:34<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:22<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bee is for book' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_10.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:52<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cee is for cat' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_11.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:53<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cee is for car' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_12.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cee is for cake' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_13.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [06:42<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:28<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:10<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cee is for cup' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_14.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [11:04<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:32<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:41<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cee is for cow' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_15.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:31<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:31<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:07<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dee is for dog' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_16.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:22<00:00,  6.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:20<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dee is for duck' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_17.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:52<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dee is for door' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_18.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:49<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dee is for drum' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_19.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:47<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dee is for doll' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_20.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:32<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ee is for egg' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_21.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:17<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [11:48:47<00:00, 531.59s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ee is for elephant' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_22.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:18<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:03<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:50<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ee is for envelope' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_23.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:57<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:40<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ee is for ear' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_24.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [11:10<00:00,  6.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:48<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:11<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ee is for elbow' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_25.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:27<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [05:50<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ef is for fish' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_26.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [04:23<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:47<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ef is for frog' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_27.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:14<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:48<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ef is for fan' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_28.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:19<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:49<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:29<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ef is for foot' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_29.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:11<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ef is for fork' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_30.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:15<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gee is for goat' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_31.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:54<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [04:06<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:25<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gee is for gift' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_32.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:33<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gee is for girl' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_33.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:54<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gee is for gum' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_34.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gee is for gold' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_35.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:07<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aitch is for hat' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_36.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:20<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:47<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:28<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aitch is for hand' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_37.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:19<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aitch is for house' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_38.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:25<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aitch is for horse' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_39.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:03<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aitch is for hill' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_40.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:07<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye is for igloo' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_41.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:09<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye is for insect' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_42.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:05<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye is for ice' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_43.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:04<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye is for island' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_44.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:23<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye is for idea' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_45.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jay is for jam' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_46.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:43<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jay is for jump' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_47.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:54<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jay is for jelly' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_48.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:02<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jay is for juice' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_49.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:52<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jay is for jacket' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_50.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:57<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kay is for kite' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_51.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:57<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kay is for king' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_52.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:54<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kay is for key' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_53.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:17<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kay is for kangaroo' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_54.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:00<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:22<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kay is for kitchen' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_55.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:57<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'el is for lion' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_56.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:38<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:24<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'el is for leaf' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_57.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:38<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:26<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'el is for lamp' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_58.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:37<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:43<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:20<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'el is for lake' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_59.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:49<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'el is for ladder' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_60.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:05<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:44<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:25<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'em is for moon' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_61.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:18<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:45<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:27<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'em is for mouse' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_62.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [03:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:22<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'em is for milk' ë¬¸ì¥ì´ 'tortoise_output_DayBirthdayDol_level1\\DayBirthdayDo_fast_63.wav'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 11/96 [00:20<02:39,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# CPUì—ì„œ ì‚¬ìš©í•  ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •\n",
    "torch.set_num_threads(20)  # ìì‹ ì˜ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì„¤ì •í•˜ì„¸ìš”.\n",
    "\n",
    "# ì•ŒíŒŒë²³ì„ ì˜ì–´ì‹ ì² ì ë°œìŒìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def replace_alphabets(text):\n",
    "    alphabet_dict = {\n",
    "        'A': 'ì—ì´', 'B': 'bee', 'C': 'cee', 'D': 'dee', 'E': 'ee',\n",
    "        'F': 'ef', 'G': 'gee', 'H': 'aitch', 'I': 'eye', 'J': 'jay',\n",
    "        'K': 'kay', 'L': 'el', 'M': 'em', 'N': 'en', 'O': 'oh',\n",
    "        'P': 'pee', 'Q': 'queue', 'R': 'ar', 'S': 'es', 'T': 'tee',\n",
    "        'U': 'you', 'V': 'vee', 'W': 'double-u', 'X': 'ex', 'Y': 'why', 'Z': 'zee'\n",
    "    }\n",
    "    words = text.split()\n",
    "    return ' '.join([alphabet_dict.get(word.upper(), word) for word in words])\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_DayBirthdayDol.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key]) for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_DayBirthdayDol_level1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ì•ŒíŒŒë²³ ë°œìŒ ì „ì²˜ë¦¬ ì ìš©\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        processed_text = replace_alphabets(text)\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(processed_text, conditioning_latents=conditioning_latents, preset=\"fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'DayBirthdayDo_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{processed_text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í›„ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## í›„ì²˜ë¦¬1\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "# ì…ë ¥ í´ë” ë° ì¶œë ¥ í´ë” ì„¤ì •\n",
    "input_folder = \"bark_output_9_enunciate\"\n",
    "output_folder = \"bark_output_9_slow_denoised\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "# ì…ë ¥ í´ë”ì— ìˆëŠ” ëª¨ë“  .wav íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ\n",
    "        audio, sr = librosa.load(input_path, sr=None)\n",
    "        \n",
    "        # ì¡ìŒ ì œê±° ì ìš©\n",
    "        reduced_noise_audio = nr.reduce_noise(y=audio, sr=sr)\n",
    "        \n",
    "        # ì¡ìŒ ì œê±°ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥\n",
    "        sf.write(output_path, reduced_noise_audio, sr, format='WAV')\n",
    "        \n",
    "        print(f\"'{filename}' íŒŒì¼ì´ ì¡ìŒ ì œê±°ë˜ì–´ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## í›„ì²˜ë¦¬2\n",
    "\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "# ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ\n",
    "input_path = \"/mnt/data/DayBirthdayDo_fast_1.wav\"\n",
    "output_path = \"/mnt/data/DayBirthdayDo_fast_1_processed.wav\"\n",
    "y, sr = librosa.load(input_path, sr=22050)\n",
    "\n",
    "# 1. ì¡ìŒ ì œê±°\n",
    "reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "# 2. í”¼ì¹˜ ì¡°ì • (ì˜ˆ: n_steps=-2ëŠ” í”¼ì¹˜ë¥¼ ì•½ê°„ ë‚®ì¶”ëŠ” ì„¤ì •)\n",
    "y_pitch_shifted = librosa.effects.pitch_shift(reduced_noise, sr, n_steps=-2)\n",
    "\n",
    "# 3. ì†ë„ ì¡°ì • (ì˜ˆ: 1.1ë°° ë¹ ë¥´ê²Œ)\n",
    "y_time_stretched = librosa.effects.time_stretch(y_pitch_shifted, rate=1.1)\n",
    "\n",
    "# 4. íŒŒì¼ ì €ì¥\n",
    "sf.write(output_path, y_time_stretched, sr)\n",
    "print(f\"í›„ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### level2 / ultra_fast / embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:09<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.49it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m processed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[enunciate] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(processed_text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     30\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelectedWorksOfE_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:587\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner\u001b[38;5;241m.\u001b[39mredact(clip\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), text)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clip\n\u001b[1;32m--> 587\u001b[0m wav_candidates \u001b[38;5;241m=\u001b[39m [potentially_redact(wav_candidate, text) \u001b[38;5;28;01mfor\u001b[39;00m wav_candidate \u001b[38;5;129;01min\u001b[39;00m wav_candidates]\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(wav_candidates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    590\u001b[0m     res \u001b[38;5;241m=\u001b[39m wav_candidates\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:585\u001b[0m, in \u001b[0;36mTextToSpeech.tts.<locals>.potentially_redact\u001b[1;34m(clip, text)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpotentially_redact\u001b[39m(clip, text):\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_redaction:\n\u001b[1;32m--> 585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner\u001b[38;5;241m.\u001b[39mredact(clip\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), text)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clip\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\utils\\wav2vec_alignment.py:144\u001b[0m, in \u001b[0;36mWav2VecAlignment.redact\u001b[1;34m(self, audio, expected_text, audio_sample_rate)\u001b[0m\n\u001b[0;32m    141\u001b[0m     last_point \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fully_split[i])\n\u001b[0;32m    143\u001b[0m bare_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fully_split)\n\u001b[1;32m--> 144\u001b[0m alignments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign(audio, bare_text, audio_sample_rate)\n\u001b[0;32m    146\u001b[0m output_audio \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nri \u001b[38;5;129;01min\u001b[39;00m non_redacted_intervals:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\utils\\wav2vec_alignment.py:62\u001b[0m, in \u001b[0;36mWav2VecAlignment.align\u001b[1;34m(self, audio, expected_text, audio_sample_rate)\u001b[0m\n\u001b[0;32m     59\u001b[0m orig_len \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     63\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     64\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mresample(audio, audio_sample_rate, \u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3156\u001b[0m         )\n\u001b[1;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1327\u001b[0m         device,\n\u001b[0;32m   1328\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1329\u001b[0m         non_blocking,\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# CPUì—ì„œ ì‚¬ìš©í•  ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •\n",
    "torch.set_num_threads(20)  # ìì‹ ì˜ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì„¤ì •í•˜ì„¸ìš”.\n",
    "\n",
    "# ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ ë° Tensorë¡œ ë³€í™˜\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_SelectedWorksOfE.npz\"\n",
    "loaded_latents = np.load(embedding_path)\n",
    "conditioning_latents = [torch.tensor(loaded_latents[key], device='cpu') for key in loaded_latents]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™” (CPU ì „ìš© ì„¤ì •)\n",
    "tts = TextToSpeech(use_deepspeed=False, kv_cache=False, half=False)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level2.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_SelectedWorksOfE_level2\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° ë° '[enunciate]' íƒœê·¸ ì¶”ê°€\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        processed_text = f\"[enunciate] {text}\"\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(processed_text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'SelectedWorksOfE_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{processed_text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m pcm_audio \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mtts_with_preset(text, conditioning_latents\u001b[38;5;241m=\u001b[39mconditioning_latents, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     36\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtortoise_test_ultra_fast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:332\u001b[0m, in \u001b[0;36mTextToSpeech.tts_with_preset\u001b[1;34m(self, text, preset, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(presets[preset])\n\u001b[0;32m    331\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs) \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:397\u001b[0m, in \u001b[0;36mTextToSpeech.tts\u001b[1;34m(self, text, voice_samples, conditioning_latents, k, verbose, use_deterministic_seed, return_deterministic_state, num_autoregressive_samples, temperature, length_penalty, repetition_penalty, top_p, max_mel_tokens, cvvp_amount, diffusion_iterations, cond_free, cond_free_k, diffusion_temperature, **hf_generate_kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m     auto_conditioning, diffusion_conditioning, auto_conds, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_conditioning_latents(voice_samples, return_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m conditioning_latents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     auto_conditioning, diffusion_conditioning \u001b[38;5;241m=\u001b[39m conditioning_latents\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     auto_conditioning, diffusion_conditioning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_random_conditioning_latents()\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# ì˜¤ë””ì˜¤ íŒŒì¼ì„ í™•ì‹¤í•˜ê²Œ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "embedding_path = \"librivox_m4b_files/AlicesAdventuresUnderground.wav\"\n",
    "audio = AudioSegment.from_file(embedding_path)\n",
    "audio = audio.set_frame_rate(22050).set_channels(1)  # ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ëª¨ë…¸ë¡œ ì„¤ì •\n",
    "audio_data = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "\n",
    "conditioning_latents = [torch.tensor(audio_data, dtype=torch.float32)]\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # ë³€í™˜í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "output_folder = \"tortoise_output_AlicesAdventuresUnderground_level1\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ì „ì²˜ë¦¬ ì ìš©\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"ultra_fast\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise import utils\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥í•  í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "output_folder = 'tortoise_output_standard_level1'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# ì—¬ëŸ¬ ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í™”ì ìƒ˜í”Œë¡œ ì‚¬ìš©\n",
    "sample_audio_files = []\n",
    "voice_samples = [utils.audio.load_audio(sample, 22050) for sample in sample_audio_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tortoiseì— ì—¬ëŸ¬ ìƒ˜í”Œë¡œ í™”ì í”„ë¡œí•„ ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# ì•ŒíŒŒë²³ì„ ì˜ì–´ì‹ ì² ì ë°œìŒìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def replace_alphabets(text):\n",
    "    alphabet_dict = {\n",
    "        'A': 'ay', 'B': 'bee', 'C': 'cee', 'D': 'dee', 'E': 'ee',\n",
    "        'F': 'ef', 'G': 'gee', 'H': 'aitch', 'I': 'eye', 'J': 'jay',\n",
    "        'K': 'kay', 'L': 'el', 'M': 'em', 'N': 'en', 'O': 'oh',\n",
    "        'P': 'pee', 'Q': 'queue', 'R': 'ar', 'S': 'es', 'T': 'tee',\n",
    "        'U': 'you', 'V': 'vee', 'W': 'double-u', 'X': 'ex', 'Y': 'why', 'Z': 'zee'\n",
    "    }\n",
    "    words = text.split()\n",
    "    return ' '.join([alphabet_dict.get(word, word) for word in words])\n",
    "\n",
    "# í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"input_level1.txt\"  # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ìŒì„± ë³€í™˜ ë° ì €ì¥\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "        text = line.strip()\n",
    "        \n",
    "        # ë¹ˆ ì¤„ì€ ê±´ë„ˆë›°ê¸°\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ë¥¼ í™”ì ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ë¡œ ìŒì„± ë³€í™˜\n",
    "        pcm_audio = tts.tts_with_preset(text, conditioning_latents=conditioning_latents, preset=\"standard\")\n",
    "\n",
    "        # PCM ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        output_path = os.path.join(output_folder, f'tortoise_test_ultra_fast_{idx+1}.wav')\n",
    "        write(output_path, 22050, np.array(pcm_audio, dtype=np.float32))\n",
    "\n",
    "        print(f\"'{text}' ë¬¸ì¥ì´ '{output_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
