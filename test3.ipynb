{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import parselmouth\n",
    "from google.cloud import speech\n",
    "from dotenv import load_dotenv\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Google Cloud Speech-to-Text API 설정\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"KEY_PATH\")\n",
    "speech_client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_in_memory(input_path, target_sr=16000):\n",
    "    \"\"\"\n",
    "    메모리에서 오디오 샘플링 속도를 변환하여 반환.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(input_path, sr=None)  # 원래 샘플링 속도로 로드\n",
    "    if sr != target_sr:\n",
    "        y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)  # 샘플링 속도 변환\n",
    "        return y_resampled, target_sr\n",
    "    return y, sr\n",
    "\n",
    "\n",
    "def extract_pitch_from_memory(y, sr):\n",
    "    \"\"\"\n",
    "    메모리 상의 오디오 데이터에서 피치를 추출.\n",
    "    \"\"\"\n",
    "    snd = parselmouth.Sound(y, sr)\n",
    "    pitch = snd.to_pitch()\n",
    "    times = pitch.xs()\n",
    "    frequencies = pitch.selected_array['frequency']\n",
    "    return times, frequencies\n",
    "\n",
    "\n",
    "def recognize_speech_from_memory(y, sr, language_code=\"en-US\"):\n",
    "    \"\"\"\n",
    "    Google Speech-to-Text API를 이용해 메모리 상의 오디오 데이터에서 단어별 타임스탬프 추출.\n",
    "    \"\"\"\n",
    "    import soundfile as sf\n",
    "    from io import BytesIO\n",
    "\n",
    "    # 메모리 상에서 변환된 데이터를 임시 WAV 파일로 저장\n",
    "    temp_buffer = BytesIO()\n",
    "    sf.write(temp_buffer, y, sr, format=\"WAV\")\n",
    "    temp_buffer.seek(0)\n",
    "    audio_content = temp_buffer.read()\n",
    "\n",
    "    # Google Speech-to-Text API 처리\n",
    "    audio = speech.RecognitionAudio(content=audio_content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=sr,\n",
    "        language_code=language_code,\n",
    "        enable_word_time_offsets=True,\n",
    "    )\n",
    "    response = speech_client.recognize(config=config, audio=audio)\n",
    "    word_timestamps = []\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            word_timestamps.append({\n",
    "                \"word\": word_info.word,\n",
    "                \"start_time\": word_info.start_time.total_seconds(),\n",
    "                \"end_time\": word_info.end_time.total_seconds()\n",
    "            })\n",
    "    return word_timestamps\n",
    "\n",
    "\n",
    "def detect_pauses(y, sr):\n",
    "    \"\"\"\n",
    "    메모리 상의 오디오 데이터를 이용해 발화 중 침묵 구간 탐지.\n",
    "    \"\"\"\n",
    "    intervals = librosa.effects.split(y, top_db=30)  # 비침묵 구간 탐지\n",
    "    pause_durations = []\n",
    "    for i in range(1, len(intervals)):\n",
    "        pause_start = intervals[i - 1][1] / sr\n",
    "        pause_end = intervals[i][0] / sr\n",
    "        pause_durations.append(pause_end - pause_start)\n",
    "    return pause_durations\n",
    "\n",
    "\n",
    "def analyze_audio(user_audio_path, ref_audio_path):\n",
    "    \"\"\"\n",
    "    주요 5가지 음성 특성 분석 및 문장 단위 결과 계산.\n",
    "    \"\"\"\n",
    "    # Step 1: 사용자와 기준 음성을 메모리에서 샘플링 속도 변환\n",
    "    y_user, sr_user = preprocess_audio_in_memory(user_audio_path)\n",
    "    y_ref, sr_ref = preprocess_audio_in_memory(ref_audio_path)\n",
    "\n",
    "    # Step 2: 단어별 타임스탬프 추출\n",
    "    word_timestamps_user = recognize_speech_from_memory(y_user, sr_user)\n",
    "    word_timestamps_reference = recognize_speech_from_memory(y_ref, sr_ref)\n",
    "\n",
    "    # 빈 데이터 확인 및 처리\n",
    "    if not word_timestamps_user:\n",
    "        print(\"Error: User audio contains no recognizable words.\")\n",
    "        return {\"Error\": \"User audio contains no recognizable words.\"}\n",
    "\n",
    "    if not word_timestamps_reference:\n",
    "        print(\"Error: Reference audio contains no recognizable words.\")\n",
    "        return {\"Error\": \"Reference audio contains no recognizable words.\"}\n",
    "\n",
    "    # 단어 리스트 추출\n",
    "    user_words = [w['word'] for w in word_timestamps_user]\n",
    "    reference_words = [w['word'] for w in word_timestamps_reference]\n",
    "\n",
    "    # Step 3: 피치 유사도 계산\n",
    "    times_user, pitch_user = extract_pitch_from_memory(y_user, sr_user)\n",
    "    times_ref, pitch_ref = extract_pitch_from_memory(y_ref, sr_ref)\n",
    "    aligned_pitch_user, aligned_pitch_ref = align_pitch_vectors(times_user, pitch_user, times_ref, pitch_ref)\n",
    "    pitch_similarity = cosine_similarity(aligned_pitch_user, aligned_pitch_ref)\n",
    "\n",
    "    # Step 4: 리듬 유사도 계산\n",
    "    rhythm_similarity = analyze_rhythm(word_timestamps_user, word_timestamps_reference)\n",
    "\n",
    "    # Step 5: 발화 속도 차이 계산\n",
    "    user_total_time = word_timestamps_user[-1]['end_time'] - word_timestamps_user[0]['start_time']\n",
    "    ref_total_time = word_timestamps_reference[-1]['end_time'] - word_timestamps_reference[0]['start_time']\n",
    "    speech_rate_user = calculate_speech_rate(word_timestamps_user, user_total_time)\n",
    "    speech_rate_ref = calculate_speech_rate(word_timestamps_reference, ref_total_time)\n",
    "    speech_rate_difference = abs(speech_rate_user - speech_rate_ref)\n",
    "\n",
    "    # Step 6: 발화 중단 빈도 차이 계산\n",
    "    pause_user = detect_pauses(y_user, sr_user)\n",
    "    pause_ref = detect_pauses(y_ref, sr_ref)\n",
    "    pause_frequency_diff = calculate_pause_frequency(pause_user, pause_ref)\n",
    "\n",
    "    # Step 7: 단어 누락 비율 계산\n",
    "    word_omission_rate = compare_word_omission(user_words, reference_words)\n",
    "\n",
    "    # 결과 집계\n",
    "    results = {\n",
    "        \"Pitch Contour Similarity\": pitch_similarity,\n",
    "        \"Rhythm Similarity\": rhythm_similarity,\n",
    "        \"Speech Rate Difference\": speech_rate_difference,\n",
    "        \"Pause Frequency Difference\": pause_frequency_diff,\n",
    "        \"Word Omission Rate\": word_omission_rate,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 문장 단위로 분석\n",
    "def analyze_sentence(user_audio_path, ref_audio_path):\n",
    "    \"\"\"문장 단위로 음성 특징을 계산.\"\"\"\n",
    "    return analyze_audio(user_audio_path, ref_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 단위 음성 특징 차이: {'Pitch Contour Similarity': 0.6105258202051731, 'Rhythm Similarity': 0.946590294908157, 'Speech Rate Difference': 0.22770398481973464, 'Pause Frequency Difference': 0, 'Word Omission Rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "user_audio = \"./test_data/child_original/jaemin_1.wav\"\n",
    "ref_audio = \"./test_data/adult_tts/tts_1.wav\"\n",
    "\n",
    "# 분석 수행\n",
    "sentence_results = analyze_sentence(user_audio, ref_audio)\n",
    "print(\"문장 단위 음성 특징 차이:\", sentence_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import parselmouth\n",
    "from scipy.interpolate import interp1d\n",
    "from google.cloud import speech\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# Google Cloud Speech-to-Text API 설정\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"KEY_PATH\")\n",
    "speech_client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number_from_filename(filename):\n",
    "    \"\"\"파일 이름에서 숫자를 추출.\"\"\"\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "def preprocess_audio(input_path, target_sr=16000):\n",
    "    \"\"\"오디오를 읽고 샘플링 속도를 변환.\"\"\"\n",
    "    y, sr = librosa.load(input_path, sr=None)\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    return y, target_sr\n",
    "\n",
    "def extract_pitch(y, sr):\n",
    "    \"\"\"피치를 시간별로 추출.\"\"\"\n",
    "    snd = parselmouth.Sound(y, sr)\n",
    "    pitch = snd.to_pitch()\n",
    "    times = pitch.xs()\n",
    "    frequencies = pitch.selected_array['frequency']\n",
    "    return times, frequencies\n",
    "\n",
    "def recognize_speech(y, sr, language_code=\"en-US\"):\n",
    "    \"\"\"Google Speech-to-Text API를 사용해 단어별 타임스탬프 추출.\"\"\"\n",
    "    import soundfile as sf\n",
    "    from io import BytesIO\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    sf.write(buffer, y, sr, format=\"WAV\")\n",
    "    buffer.seek(0)\n",
    "    audio = speech.RecognitionAudio(content=buffer.read())\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=sr,\n",
    "        language_code=language_code,\n",
    "        enable_word_time_offsets=True,\n",
    "    )\n",
    "    response = speech_client.recognize(config=config, audio=audio)\n",
    "\n",
    "    word_timestamps = []\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            word_timestamps.append({\n",
    "                \"word\": word_info.word,\n",
    "                \"start_time\": word_info.start_time.total_seconds(),\n",
    "                \"end_time\": word_info.end_time.total_seconds(),\n",
    "            })\n",
    "    return word_timestamps\n",
    "\n",
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    \"\"\"벡터 간 코사인 유사도 계산.\"\"\"\n",
    "    if len(vec1) == 0 or len(vec2) == 0:\n",
    "        return 0.0\n",
    "    min_len = min(len(vec1), len(vec2))  # 최소 길이에 맞춤\n",
    "    vec1 = vec1[:min_len]\n",
    "    vec2 = vec2[:min_len]\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def calculate_word_based_pitch_similarity(word_timestamps, y, sr):\n",
    "    \"\"\"단어별 음조(피치) 유사도 계산.\"\"\"\n",
    "    pitch_similarities = []\n",
    "    times, frequencies = extract_pitch(y, sr)\n",
    "\n",
    "    for word in word_timestamps:\n",
    "        start_time = word[\"start_time\"]\n",
    "        end_time = word[\"end_time\"]\n",
    "\n",
    "        mask = (times >= start_time) & (times <= end_time)\n",
    "        word_pitch = frequencies[mask]\n",
    "        if len(word_pitch) > 0:\n",
    "            pitch_similarities.append(word_pitch.mean())  # 평균 피치\n",
    "\n",
    "    return pitch_similarities\n",
    "\n",
    "def calculate_rhythm_similarity(word_timestamps):\n",
    "    \"\"\"단어별 리듬 유사도 계산.\"\"\"\n",
    "    gaps = []\n",
    "    for i in range(1, len(word_timestamps)):\n",
    "        gap = word_timestamps[i][\"start_time\"] - word_timestamps[i - 1][\"end_time\"]\n",
    "        gaps.append(gap)\n",
    "\n",
    "    return gaps\n",
    "\n",
    "def analyze_audio(user_audio_path, ref_audio_path):\n",
    "    \"\"\"사용자와 기준 음성을 분석하여 결과 반환.\"\"\"\n",
    "    # 1. 오디오 전처리 (샘플링 속도 통일)\n",
    "    y_user, sr_user = preprocess_audio(user_audio_path)\n",
    "    y_ref, sr_ref = preprocess_audio(ref_audio_path)\n",
    "\n",
    "    # 2. 음성 텍스트 인식\n",
    "    user_timestamps = recognize_speech(y_user, sr_user)\n",
    "    ref_timestamps = recognize_speech(y_ref, sr_ref)\n",
    "\n",
    "    if len(user_timestamps) != len(ref_timestamps):\n",
    "        print(f\"Warning: Word count mismatch between user ({len(user_timestamps)}) and reference ({len(ref_timestamps)}).\")\n",
    "\n",
    "    # 3. 피치 패턴 유사도\n",
    "    user_pitch = calculate_word_based_pitch_similarity(user_timestamps, y_user, sr_user)\n",
    "    ref_pitch = calculate_word_based_pitch_similarity(ref_timestamps, y_ref, sr_ref)\n",
    "    pitch_similarity = calculate_cosine_similarity(user_pitch, ref_pitch)\n",
    "\n",
    "    # 4. 리듬 유사도\n",
    "    user_rhythm = calculate_rhythm_similarity(user_timestamps)\n",
    "    ref_rhythm = calculate_rhythm_similarity(ref_timestamps)\n",
    "    rhythm_similarity = calculate_cosine_similarity(user_rhythm, ref_rhythm)\n",
    "\n",
    "    # 5. 발화 속도\n",
    "    user_speed = len(user_timestamps) / (user_timestamps[-1][\"end_time\"] - user_timestamps[0][\"start_time\"])\n",
    "    ref_speed = len(ref_timestamps) / (ref_timestamps[-1][\"end_time\"] - ref_timestamps[0][\"start_time\"])\n",
    "    speed_ratio = abs(user_speed / ref_speed)\n",
    "\n",
    "    # 6. 발화 중단 빈도\n",
    "    user_pauses = calculate_rhythm_similarity(user_timestamps)\n",
    "    ref_pauses = calculate_rhythm_similarity(ref_timestamps)\n",
    "    pause_similarity = calculate_cosine_similarity(user_pauses, ref_pauses)\n",
    "\n",
    "    # 7. 단어 누락 및 잘못 인식된 단어\n",
    "    user_words = [word[\"word\"] for word in user_timestamps]\n",
    "    ref_words = [word[\"word\"] for word in ref_timestamps]\n",
    "    missed_words = list(set(ref_words) - set(user_words))\n",
    "    mispronounced_words = list(set(user_words) - set(ref_words))\n",
    "\n",
    "    return {\n",
    "        \"Pitch Similarity\": pitch_similarity,\n",
    "        \"Rhythm Similarity\": rhythm_similarity,\n",
    "        \"Speed Ratio\": speed_ratio,\n",
    "        \"Pause Similarity\": pause_similarity,\n",
    "        \"Missed Words\": missed_words,\n",
    "        \"Mispronounced Words\": mispronounced_words,\n",
    "    }\n",
    "\n",
    "def compare_audio_folders(user_folder, ref_folder, output_file=\"results.json\"):\n",
    "    \"\"\"폴더 간 음성 파일 비교.\"\"\"\n",
    "    user_files = sorted(os.listdir(user_folder), key=extract_number_from_filename)\n",
    "    ref_files = sorted(os.listdir(ref_folder), key=extract_number_from_filename)\n",
    "\n",
    "    if len(user_files) != len(ref_files):\n",
    "        raise ValueError(\"폴더 간 파일 수가 일치하지 않습니다.\")\n",
    "\n",
    "    results = []\n",
    "    for user_file, ref_file in zip(user_files, ref_files):\n",
    "        user_audio_path = os.path.join(user_folder, user_file)\n",
    "        ref_audio_path = os.path.join(ref_folder, ref_file)\n",
    "        print(f\"Processing: {user_file} vs {ref_file}\")\n",
    "        result = analyze_audio(user_audio_path, ref_audio_path)\n",
    "        result[\"File Pair\"] = f\"{user_file} vs {ref_file}\"\n",
    "        results.append(result)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    user_folder = \"./test_data/child_original_audio_100\"\n",
    "    ref_folder = \"./test_data/tts_tortoise_audio_100\"\n",
    "    compare_audio_folders(user_folder, ref_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822489.wav vs sentence_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11828\\3065845322.py:55: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822502.wav vs sentence_2.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822529.wav vs sentence_3.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822580.wav vs sentence_4.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822594.wav vs sentence_5.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822603.wav vs sentence_6.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822635.wav vs sentence_7.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822655.wav vs sentence_8.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822681.wav vs sentence_9.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822693.wav vs sentence_10.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822705.wav vs sentence_11.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822723.wav vs sentence_12.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822746.wav vs sentence_13.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822759.wav vs sentence_14.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822782.wav vs sentence_15.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822831.wav vs sentence_16.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822849.wav vs sentence_17.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822866.wav vs sentence_18.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822926.wav vs sentence_19.wav\n",
      "Warning: Word count mismatch between user (8) and reference (9).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822937.wav vs sentence_20.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822956.wav vs sentence_21.wav\n",
      "Warning: Word count mismatch between user (7) and reference (8).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822975.wav vs sentence_22.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04822996.wav vs sentence_23.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823011.wav vs sentence_24.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823045.wav vs sentence_25.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823065.wav vs sentence_26.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823086.wav vs sentence_27.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823099.wav vs sentence_28.wav\n",
      "Warning: Word count mismatch between user (5) and reference (4).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823163.wav vs sentence_29.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823175.wav vs sentence_30.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823185.wav vs sentence_31.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823214.wav vs sentence_32.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823263.wav vs sentence_33.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823288.wav vs sentence_34.wav\n",
      "Warning: Word count mismatch between user (7) and reference (8).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823314.wav vs sentence_35.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823336.wav vs sentence_36.wav\n",
      "Warning: Word count mismatch between user (8) and reference (9).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823352.wav vs sentence_37.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823371.wav vs sentence_38.wav\n",
      "Warning: Word count mismatch between user (7) and reference (4).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823396.wav vs sentence_39.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823407.wav vs sentence_40.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823418.wav vs sentence_41.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823460.wav vs sentence_42.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823480.wav vs sentence_43.wav\n",
      "Warning: Word count mismatch between user (6) and reference (5).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823504.wav vs sentence_44.wav\n",
      "Warning: Word count mismatch between user (10) and reference (9).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823534.wav vs sentence_45.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823583.wav vs sentence_46.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823596.wav vs sentence_47.wav\n",
      "Warning: Word count mismatch between user (6) and reference (5).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823637.wav vs sentence_48.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823656.wav vs sentence_49.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823680.wav vs sentence_50.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823698.wav vs sentence_51.wav\n",
      "Warning: Word count mismatch between user (3) and reference (5).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823720.wav vs sentence_52.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823754.wav vs sentence_53.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823774.wav vs sentence_54.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823797.wav vs sentence_55.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823842.wav vs sentence_56.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823869.wav vs sentence_57.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823901.wav vs sentence_58.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823926.wav vs sentence_59.wav\n",
      "Warning: Word count mismatch between user (9) and reference (10).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04823975.wav vs sentence_60.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824002.wav vs sentence_61.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824023.wav vs sentence_62.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824058.wav vs sentence_63.wav\n",
      "Warning: Word count mismatch between user (10) and reference (9).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824073.wav vs sentence_64.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824093.wav vs sentence_65.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824121.wav vs sentence_66.wav\n",
      "Warning: Word count mismatch between user (7) and reference (6).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824136.wav vs sentence_67.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824172.wav vs sentence_68.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824207.wav vs sentence_69.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824224.wav vs sentence_70.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824237.wav vs sentence_71.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824254.wav vs sentence_72.wav\n",
      "Warning: Word count mismatch between user (8) and reference (9).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824285.wav vs sentence_73.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824310.wav vs sentence_74.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824322.wav vs sentence_75.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824353.wav vs sentence_76.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824376.wav vs sentence_77.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824400.wav vs sentence_78.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824452.wav vs sentence_79.wav\n",
      "Warning: Word count mismatch between user (7) and reference (6).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824482.wav vs sentence_80.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824522.wav vs sentence_81.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824538.wav vs sentence_82.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04824553.wav vs sentence_83.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843466.wav vs sentence_84.wav\n",
      "Warning: Word count mismatch between user (6) and reference (5).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843496.wav vs sentence_85.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843515.wav vs sentence_86.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843530.wav vs sentence_87.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843541.wav vs sentence_88.wav\n",
      "Warning: Word count mismatch between user (1) and reference (3).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843556.wav vs sentence_89.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843578.wav vs sentence_90.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843592.wav vs sentence_91.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843607.wav vs sentence_92.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843627.wav vs sentence_93.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843656.wav vs sentence_94.wav\n",
      "Warning: Word count mismatch between user (11) and reference (10).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843682.wav vs sentence_95.wav\n",
      "Warning: Word count mismatch between user (12) and reference (11).\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843715.wav vs sentence_96.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843726.wav vs sentence_97.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843740.wav vs sentence_98.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843754.wav vs sentence_99.wav\n",
      "Processing: E0001A671-BFG33-L1N2D1-E-F5NX-04843766.wav vs sentence_100.wav\n",
      "Results saved to results.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epa_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
